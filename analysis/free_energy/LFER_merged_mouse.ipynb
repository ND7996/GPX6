{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2ac62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating merged LFER plots with single R²...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hp/results/MOUSE/distance_analysis_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 340\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;66;03m# Create merged plots with single R²\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCreating merged LFER plots with single R²...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m fig, axes, data = \u001b[43mcreate_merged_lfer_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m                                          \u001b[49m\u001b[43merror_scale_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mcreate_merged_lfer_plots\u001b[39m\u001b[34m(csv_path, save_paths, error_scale_factor)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03mCreate merged LFER plots: one with error bars and one without, with single R²\u001b[39;00m\n\u001b[32m     68\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m \u001b[33;03merror_scale_factor (float): Scale factor for error bars\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows from CSV\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Show all column names to help debug\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/hp/results/MOUSE/distance_analysis_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager as fm\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "import re\n",
    "import os\n",
    "\n",
    "def extract_level_number(level_str):\n",
    "    \"\"\"Extract numeric level from level string - improved version\"\"\"\n",
    "    import re\n",
    "    \n",
    "    if pd.isna(level_str):\n",
    "        return None\n",
    "    \n",
    "    # Convert to string if not already\n",
    "    level_str = str(level_str).lower().strip()\n",
    "    \n",
    "    # Try different patterns\n",
    "    patterns = [\n",
    "        r'level\\s*(\\d+)',  # level0, level 0, level_0\n",
    "        r'lvl\\s*(\\d+)',    # lvl0, lvl 0\n",
    "        r'^(\\d+)$',        # just a number\n",
    "        r'(\\d+)',          # any number in the string\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, level_str)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def parse_value_with_error(value_str):\n",
    "    \"\"\"\n",
    "    Parse a string like '15.59 ± 0.94' and return (value, error)\n",
    "    If no error is found, return (value, 0.0)\n",
    "    \"\"\"\n",
    "    if pd.isna(value_str):\n",
    "        return None, None\n",
    "    \n",
    "    value_str = str(value_str).strip()\n",
    "    \n",
    "    # Look for pattern: number ± number\n",
    "    pattern = r'(-?\\d+\\.?\\d*)\\s*[±]\\s*(\\d+\\.?\\d*)'\n",
    "    match = re.search(pattern, value_str)\n",
    "    \n",
    "    if match:\n",
    "        value = float(match.group(1))\n",
    "        error = float(match.group(2))\n",
    "        return value, error\n",
    "    else:\n",
    "        # Try to extract just the number if no ± found\n",
    "        number_pattern = r'(-?\\d+\\.?\\d*)'\n",
    "        number_match = re.search(number_pattern, value_str)\n",
    "        if number_match:\n",
    "            value = float(number_match.group(1))\n",
    "            return value, 0.0\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "def create_merged_lfer_plots(csv_path, save_paths=None, error_scale_factor=0.3):\n",
    "    \"\"\"\n",
    "    Create merged LFER plots: one with error bars and one without, with single R²\n",
    "    \n",
    "    Parameters:\n",
    "    csv_path (str): Path to the CSV file\n",
    "    save_paths (list): List of directory paths where the plot should be saved\n",
    "    error_scale_factor (float): Scale factor for error bars\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded {len(df)} rows from CSV\")\n",
    "    \n",
    "    # Show all column names to help debug\n",
    "    print(f\"\\nAll columns in CSV:\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"  {i}: '{col}'\")\n",
    "    \n",
    "    # Check for raw data columns that might contain error information\n",
    "    raw_columns = [col for col in df.columns if 'raw' in col.lower()]\n",
    "    print(f\"\\nFound raw data columns: {raw_columns}\")\n",
    "    \n",
    "    # Parse raw data columns to extract values and errors\n",
    "    if 'dG_star_raw' in df.columns:\n",
    "        print(\"Parsing dG_star_raw column...\")\n",
    "        df[['dg_star_parsed', 'dg_star_stderr']] = df['dG_star_raw'].apply(\n",
    "            lambda x: pd.Series(parse_value_with_error(x))\n",
    "        )\n",
    "    \n",
    "    if 'dG0_raw' in df.columns:\n",
    "        print(\"\\nParsing dG0_raw column...\")\n",
    "        df[['dg0_parsed', 'dg0_stderr']] = df['dG0_raw'].apply(\n",
    "            lambda x: pd.Series(parse_value_with_error(x))\n",
    "        )\n",
    "    \n",
    "    # Standardize column names - now prioritize parsed values\n",
    "    column_mapping = {\n",
    "        'Mean_dG_star': 'dg_star_mean',\n",
    "        'Mean_dG0': 'dg0_mean', \n",
    "        'Mutation': 'mutation',\n",
    "        'mean_dg_star': 'dg_star_mean',\n",
    "        'mean_dg0': 'dg0_mean',\n",
    "    }\n",
    "    \n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        if old_name in df.columns:\n",
    "            print(f\"Renaming: '{old_name}' -> '{new_name}'\")\n",
    "            df = df.rename(columns={old_name: new_name})\n",
    "    \n",
    "    # Decide which values to use - prefer parsed values from raw data\n",
    "    if 'dg_star_parsed' in df.columns and not df['dg_star_parsed'].isna().all():\n",
    "        df['dg_star'] = df['dg_star_parsed']\n",
    "        print(\"Using parsed dG_star values from raw data\")\n",
    "    elif 'dg_star_mean' in df.columns:\n",
    "        df['dg_star'] = df['dg_star_mean']\n",
    "        print(\"Using mean dG_star values\")\n",
    "    else:\n",
    "        print(\"ERROR: No dG_star column found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    if 'dg0_parsed' in df.columns and not df['dg0_parsed'].isna().all():\n",
    "        df['dg0'] = df['dg0_parsed']\n",
    "        print(\"Using parsed dG0 values from raw data\")\n",
    "    elif 'dg0_mean' in df.columns:\n",
    "        df['dg0'] = df['dg0_mean']\n",
    "        print(\"Using mean dG0 values\")\n",
    "    else:\n",
    "        print(\"ERROR: No dG0 column found!\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Check for error columns\n",
    "    has_dg_star_error = 'dg_star_stderr' in df.columns and not df['dg_star_stderr'].isna().all()\n",
    "    has_dg0_error = 'dg0_stderr' in df.columns and not df['dg0_stderr'].isna().all()\n",
    "    \n",
    "    print(f\"\\nError bar availability:\")\n",
    "    print(f\"  ΔG‡ standard error: {'Available' if has_dg_star_error else 'Not found'}\")\n",
    "    print(f\"  ΔG° standard error: {'Available' if has_dg0_error else 'Not found'}\")\n",
    "    \n",
    "    # Extract level numbers\n",
    "    df['Level_Numeric'] = df['Level'].apply(extract_level_number)\n",
    "    \n",
    "    # Clean data - include error columns if they exist\n",
    "    required_cols = ['dg_star', 'dg0', 'mutation', 'Level_Numeric']\n",
    "    df_clean = df.dropna(subset=required_cols).copy()\n",
    "    \n",
    "    # Handle missing error values by setting them to 0\n",
    "    if has_dg_star_error:\n",
    "        df_clean['dg_star_stderr'] = df_clean['dg_star_stderr'].fillna(0)\n",
    "    else:\n",
    "        df_clean['dg_star_stderr'] = 0\n",
    "        \n",
    "    if has_dg0_error:\n",
    "        df_clean['dg0_stderr'] = df_clean['dg0_stderr'].fillna(0)\n",
    "    else:\n",
    "        df_clean['dg0_stderr'] = 0\n",
    "    \n",
    "    # Apply error scaling factor\n",
    "    if has_dg_star_error:\n",
    "        df_clean['dg_star_stderr_scaled'] = df_clean['dg_star_stderr'] * error_scale_factor\n",
    "    else:\n",
    "        df_clean['dg_star_stderr_scaled'] = 0\n",
    "        \n",
    "    # No horizontal error bars - only vertical\n",
    "    df_clean['dg0_stderr_scaled'] = 0\n",
    "    \n",
    "    print(f\"After cleaning: {len(df_clean)} rows remaining\")\n",
    "    \n",
    "    # Get unique levels that actually exist\n",
    "    unique_levels = sorted(df_clean['Level_Numeric'].unique())\n",
    "    print(f\"Numeric levels found: {unique_levels}\")\n",
    "    \n",
    "    # Define distinct colors for levels\n",
    "    level_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                   '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    \n",
    "    n_levels = len(unique_levels)\n",
    "    if n_levels == 1:\n",
    "        level_alphas = [0.7]\n",
    "        level_sizes = [100]\n",
    "        level_colors_mapped = [level_colors[0]]\n",
    "    else:\n",
    "        level_alphas = np.linspace(0.6, 0.9, n_levels)\n",
    "        level_sizes = np.linspace(80, 120, n_levels)\n",
    "        level_colors_mapped = [level_colors[i % len(level_colors)] for i in range(n_levels)]\n",
    "    \n",
    "    # Create level to visual mapping\n",
    "    level_visual_map = {}\n",
    "    for i, level in enumerate(unique_levels):\n",
    "        level_visual_map[level] = {\n",
    "            'alpha': level_alphas[i],\n",
    "            'size': level_sizes[i],\n",
    "            'color': level_colors_mapped[i]\n",
    "        }\n",
    "    \n",
    "    # Calculate SINGLE R² for all data (merged)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(df_clean['dg0'], df_clean['dg_star'])\n",
    "    r_squared = r_value**2\n",
    "    \n",
    "    # Create merged subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), facecolor='white')\n",
    "    \n",
    "    # Plot 1: With error bars\n",
    "    for level in unique_levels:\n",
    "        level_data = df_clean[df_clean['Level_Numeric'] == level]\n",
    "        \n",
    "        # Check if we have meaningful error values\n",
    "        has_meaningful_dg_star_err = (level_data['dg_star_stderr_scaled'] > 0).any()\n",
    "        \n",
    "        # Plot error bars first (behind points)\n",
    "        if has_meaningful_dg_star_err:\n",
    "            yerr = level_data['dg_star_stderr_scaled']\n",
    "            xerr = None  # No horizontal error bars\n",
    "            \n",
    "            ax1.errorbar(level_data['dg0'], level_data['dg_star'], \n",
    "                       xerr=xerr, yerr=yerr,\n",
    "                       fmt='none',\n",
    "                       ecolor=level_visual_map[level]['color'], \n",
    "                       alpha=0.5,\n",
    "                       capsize=2,\n",
    "                       capthick=1,\n",
    "                       elinewidth=1,\n",
    "                       zorder=2)\n",
    "        \n",
    "        # Plot the actual data points on top\n",
    "        ax1.scatter(level_data['dg0'], level_data['dg_star'], \n",
    "                   c=level_visual_map[level]['color'], \n",
    "                   s=level_visual_map[level]['size'],\n",
    "                   alpha=level_visual_map[level]['alpha'],\n",
    "                   marker='o',\n",
    "                   edgecolors='black', linewidth=0.8,\n",
    "                   label=f'Level {level}',\n",
    "                   zorder=5)\n",
    "    \n",
    "    # Plot trend line for error bar plot\n",
    "    x_range = np.linspace(df_clean['dg0'].min(), df_clean['dg0'].max(), 100)\n",
    "    y_trend = slope * x_range + intercept\n",
    "    ax1.plot(x_range, y_trend, 'r-', linewidth=2.5, alpha=0.9, zorder=3)\n",
    "    \n",
    "    # Add R² to error bar plot\n",
    "    ax1.text(0.05, 0.95, f'R² = {r_squared:.3f}', transform=ax1.transAxes, \n",
    "            verticalalignment='top', fontsize=14, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax1.set_xlabel('ΔG° (kcal/mol)', fontweight='bold', fontsize=16)\n",
    "    ax1.set_ylabel('ΔG‡ (kcal/mol)', fontweight='bold', fontsize=16)\n",
    "    ax1.set_title('LFER Plot with Error Bars', fontweight='bold', fontsize=18)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "    \n",
    "    # Plot 2: Without error bars (simple scatter)\n",
    "    for level in unique_levels:\n",
    "        level_data = df_clean[df_clean['Level_Numeric'] == level]\n",
    "        \n",
    "        ax2.scatter(level_data['dg0'], level_data['dg_star'], \n",
    "                   c=level_visual_map[level]['color'], \n",
    "                   s=level_visual_map[level]['size'],\n",
    "                   alpha=level_visual_map[level]['alpha'],\n",
    "                   marker='o',\n",
    "                   edgecolors='black', linewidth=0.8,\n",
    "                   label=f'Level {level}',\n",
    "                   zorder=5)\n",
    "    \n",
    "    # Plot the SAME trend line for scatter plot (same R²)\n",
    "    ax2.plot(x_range, y_trend, 'r-', linewidth=2.5, alpha=0.9, zorder=3)\n",
    "    \n",
    "    # Add the SAME R² to scatter plot\n",
    "    ax2.text(0.05, 0.95, f'R² = {r_squared:.3f}', transform=ax2.transAxes, \n",
    "            verticalalignment='top', fontsize=14, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    ax2.set_xlabel('ΔG° (kcal/mol)', fontweight='bold', fontsize=16)\n",
    "    ax2.set_ylabel('ΔG‡ (kcal/mol)', fontweight='bold', fontsize=16)\n",
    "    ax2.set_title('LFER Plot (Scatter Only)', fontweight='bold', fontsize=18)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=14)\n",
    "    \n",
    "    # Add overall title with single R²\n",
    "    plt.suptitle(f'Linear Free Energy Relationship - Combined R² = {r_squared:.3f}', \n",
    "                fontsize=20, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plots if save_paths are provided\n",
    "    if save_paths:\n",
    "        for save_path in save_paths:\n",
    "            # Create directory if it doesn't exist\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            \n",
    "            # Define filenames\n",
    "            png_filename = \"merged_LFER_plots.png\"\n",
    "            pdf_filename = \"merged_LFER_plots.pdf\"\n",
    "            \n",
    "            full_png_path = os.path.join(save_path, png_filename)\n",
    "            full_pdf_path = os.path.join(save_path, pdf_filename)\n",
    "            \n",
    "            # Save with high quality\n",
    "            fig.savefig(full_png_path, dpi=300, bbox_inches='tight', \n",
    "                       facecolor='white', edgecolor='none')\n",
    "            fig.savefig(full_pdf_path, dpi=300, bbox_inches='tight', \n",
    "                       facecolor='white', edgecolor='none')\n",
    "            \n",
    "            print(f\"Merged plots saved to: {full_png_path}\")\n",
    "            print(f\"PDF saved to: {full_pdf_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print(f\"\\n--- MERGED PLOTS SUMMARY ---\")\n",
    "    print(f\"Single R² value calculated from all data: {r_squared:.3f}\")\n",
    "    print(f\"Levels in your data: {unique_levels}\")\n",
    "    print(f\"Total data points: {len(df_clean)}\")\n",
    "    print(f\"Linear regression equation: ΔG‡ = {slope:.3f} × ΔG° + {intercept:.3f}\")\n",
    "    print(f\"p-value: {p_value:.6f}\")\n",
    "    \n",
    "    # Error bar summary\n",
    "    print(f\"\\n--- ERROR BAR CONFIGURATION ---\")\n",
    "    print(f\"Left plot: WITH error bars (vertical only)\")\n",
    "    print(f\"Right plot: WITHOUT error bars (simple scatter)\")\n",
    "    print(f\"Both plots share the SAME R² value: {r_squared:.3f}\")\n",
    "    \n",
    "    return fig, (ax1, ax2), df_clean\n",
    "\n",
    "# Example usage with merged plots:\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/home/hp/results/MOUSE/distance_analysis_data.csv\"\n",
    "    save_paths = [\n",
    "        \"/home/hp/nayanika/github/GPX6/figures\",\n",
    "        \"/home/hp/nayanika/github/Article-GPX6-EVB/Figures\"\n",
    "    ]\n",
    "    \n",
    "    # Create merged plots with single R²\n",
    "    print(\"Creating merged LFER plots with single R²...\")\n",
    "    fig, axes, data = create_merged_lfer_plots(csv_path, save_paths=save_paths, \n",
    "                                              error_scale_factor=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
